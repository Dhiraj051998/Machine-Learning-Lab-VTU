{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.30122757 0.34090909 0.61524501 0.32657658 0.37491091 0.30827341\n",
      "  0.17380601]\n",
      " [0.76770538 0.78099174 0.81306715 0.62331081 0.87455453 0.59276548\n",
      "  0.66962088]\n",
      " [0.42115203 0.46900826 0.63339383 0.45777027 0.49750535 0.17733945\n",
      "  0.41408173]\n",
      " [0.3871577  0.42975207 0.65154265 0.37387387 0.44832502 0.36678412\n",
      "  0.3446578 ]\n",
      " [0.06043437 0.08471074 0.46551724 0.10698198 0.13613685 0.87881782\n",
      "  0.21565731]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 1 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0ed7d719e86d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;31m#determine the number of classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m \u001b[0mtrain_one_hot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_OH\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[0mn_hidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-0ed7d719e86d>\u001b[0m in \u001b[0;36mconvert_to_OH\u001b[1;34m(data, num_classes)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;31m#create an array to store the one hot vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mone_hot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m     \u001b[0mone_hot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for axis 1 with size 3"
     ]
    }
   ],
   "source": [
    "from random import seed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def split_dataset(dataset, train_perc=0.8,test_perc = 0.2):\n",
    "    np.random.shuffle(dataset)\n",
    "    data_len = len(dataset)\n",
    "    train_index = int(data_len*train_perc) # last index from the dataset array that will go into training\n",
    "    \n",
    "    train = dataset[:train_index,:]  \n",
    "    test = dataset[train_index:,:] \n",
    "    return (train, test)\n",
    "\n",
    "def sigmoid(activation):\n",
    "    return 1.0 / (1.0 + np.exp(-activation))\n",
    "    \n",
    "def compute_loss(prediction, actual):\n",
    "    #return -sum(actual*log(prediction))\n",
    "    return 0.5*np.sum((actual.T-prediction)*(actual.T-prediction))\n",
    "\n",
    "def back_prop(train_X,W1,W2,layer1_output,layer2_output,actual_output):\n",
    "    #find error in output unit\n",
    "    difference = actual_output.T - layer2_output    \n",
    "    delta_output = layer2_output*(1-layer2_output)*difference\n",
    "    delta_hidden = layer1_output*(1-layer1_output)*W2.T.dot(delta_output)\n",
    "    deltaW2 = lr*(delta_output.dot(layer1_output.T)/n_train) \n",
    "    deltaW1 = lr*(delta_hidden.dot(train_X)/n_train) \n",
    "    \n",
    "    return (deltaW1,deltaW2)\n",
    "    \n",
    "def train_network(train_X, train_y):\n",
    "    n_input = train_X.shape[1]  # the number of columns in the training data\n",
    "    W1=np.random.random((n_hidden,n_input))\n",
    "    W2=np.random.random((num_classes,n_hidden ))\n",
    "    for epoch in range(n_epoch):\n",
    "        layer1_output = sigmoid(W1.dot(train_X.T))\n",
    "        layer2_output = sigmoid(W2.dot(layer1_output))\n",
    "        \n",
    "        (deltaW1,deltaW2)= back_prop(train_X,W1,W2,layer1_output,layer2_output,train_y)\n",
    "        print(deltaW1[:5])\n",
    "        W2 = W2+deltaW2\n",
    "        W1 = W1+deltaW1\n",
    "        if epoch%1000 == 0:\n",
    "            loss = compute_loss(layer2_output,train_y)\n",
    "            print(str.format('Loss in {0}th epoch is {1}',epoch,loss))\n",
    "        \n",
    "            \n",
    "    return (W1,W2)\n",
    "\n",
    "def evaluate(test_X,test_y,params):\n",
    "    (W1,W2) = params\n",
    "    layer1_output = sigmoid(W1.dot(test_X.T))\n",
    "    final = sigmoid(W2.dot(layer1_output))\n",
    "    \n",
    "    prediction = final.argmax(axis=0)    \n",
    "    return np.sum(prediction==test_y)/len(test_y)    \n",
    "\n",
    "def convert_to_OH(data,num_classes):\n",
    "    #create an array to store the one hot vectors\n",
    "    one_hot = np.zeros((len(data),num_classes))\n",
    "    one_hot[np.arange(len(data)),data] = 1\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "# load and prepare data\n",
    "#filename = 'seeds_dataset.csv'\n",
    "filename = 'dataset.csv'\n",
    "df = pd.read_csv(filename,dtype=np.float64)\n",
    "dataset = np.array(df)\n",
    "\n",
    "#normalize data\n",
    "min_data = dataset.min(axis = 0)\n",
    "max_data = dataset.max(axis = 0)\n",
    "\n",
    "#normalize all fields except the last column(class)\n",
    "dataset[:,0:-1] = (dataset[:,0:-1] - min_data[0:-1])/(max_data[0:-1] - min_data[0:-1])\n",
    "(train, test) = split_dataset(dataset)\n",
    "print(train[:5,:-1])\n",
    "#train = dataset \n",
    "n_train = len(train)\n",
    "n_test = len(test)\n",
    "\n",
    "# evaluate algorithm\n",
    "lr = 0.8\n",
    "n_epoch =15000\n",
    "\n",
    "#determine the number of classes\n",
    "num_classes = len(np.unique(dataset[:,-1]))\n",
    "train_one_hot = convert_to_OH(train[:,-1].astype(int),num_classes)\n",
    "\n",
    "n_hidden = 15\n",
    "\n",
    "params = train_network(train[:,:-1],train_one_hot) \n",
    "accuracy = evaluate(test[:,:-1],test[:,-1],params)*100\n",
    "print('Mean Accuracy: %.3f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
